{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114753f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (4.52.3)\n",
      "Collecting peft\n",
      "  Downloading peft-0.15.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: datasets in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (0.32.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from peft) (1.7.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from datasets) (3.11.18)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from aiohttp->datasets) (1.20.0)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp->datasets) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading peft-0.15.2-py3-none-any.whl (411 kB)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch transformers peft datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8607b35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff895191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gguf\n",
      "  Downloading gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: peft in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from gguf) (2.2.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from gguf) (6.0.2)\n",
      "Collecting sentencepiece<=0.2.0,>=0.1.98 (from gguf)\n",
      "  Using cached sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-8eb7c4ow\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-8eb7c4ow\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-8eb7c4ow\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-8eb7c4ow\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m414\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1039\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1551\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] The system cannot find the file specified\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install gguf peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e283c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gguf\n",
      "  Using cached gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from gguf) (2.2.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abhishekkollojuv-sof\\abhishek programs\\project-11\\venv\\lib\\site-packages (from gguf) (6.0.2)\n",
      "Collecting sentencepiece<=0.2.0,>=0.1.98 (from gguf)\n",
      "  Using cached sentencepiece-0.2.0.tar.gz (2.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [48 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-s6ye4v0a\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-s6ye4v0a\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-s6ye4v0a\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\AbhishekKollojuV-Sof\\AppData\\Local\\Temp\\pip-build-env-s6ye4v0a\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m128\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m414\u001b[0m, in \u001b[35mcheck_call\u001b[0m\n",
      "          retcode = call(*popenargs, **kwargs)\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m395\u001b[0m, in \u001b[35mcall\u001b[0m\n",
      "          with \u001b[31mPopen\u001b[0m\u001b[1;31m(*popenargs, **kwargs)\u001b[0m as p:\n",
      "               \u001b[31m~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1039\u001b[0m, in \u001b[35m__init__\u001b[0m\n",
      "          \u001b[31mself._execute_child\u001b[0m\u001b[1;31m(args, executable, preexec_fn, close_fds,\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mpass_fds, cwd, env,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<5 lines>...\n",
      "                              \u001b[1;31mgid, gids, uid, umask,\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                              \u001b[1;31mstart_new_session, process_group)\u001b[0m\n",
      "                              \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Python313\\Lib\\subprocess.py\"\u001b[0m, line \u001b[35m1551\u001b[0m, in \u001b[35m_execute_child\u001b[0m\n",
      "          hp, ht, pid, tid = \u001b[31m_winapi.CreateProcess\u001b[0m\u001b[1;31m(executable, args,\u001b[0m\n",
      "                             \u001b[31m~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "                                   \u001b[1;31m# no special security\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "          ...<4 lines>...\n",
      "                                   \u001b[1;31mcwd,\u001b[0m\n",
      "                                   \u001b[1;31m^^^^\u001b[0m\n",
      "                                   \u001b[1;31mstartupinfo)\u001b[0m\n",
      "                                   \u001b[1;31m^^^^^^^^^^^^\u001b[0m\n",
      "      \u001b[1;35mFileNotFoundError\u001b[0m: \u001b[35m[WinError 2] The system cannot find the file specified\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "pip install gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ea0819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GGUF file: C:\\Users\\AbhishekKollojuV-Sof\\.ollama\\models\\blobs\\sha256-0611867ea67b05e39cbe647353a4d5ebe04598cdb29fe8d99d42baab00e1c724\n",
      "Tokenizer saved to c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\LIM\\qwen2-0.5b-pytorch\n",
      "Simulated PyTorch model saved to c:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\LIM\\qwen2-0.5b-pytorch\n",
      "Error loading model or tokenizer: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n",
      "Error in main execution: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 167\u001b[39m\n\u001b[32m    164\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 157\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    156\u001b[39m     model_path = locate_and_convert_gguf()\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m     model, tokenizer = \u001b[43mload_model_and_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     tokenized_dataset = prepare_dataset(tokenizer)\n\u001b[32m    159\u001b[39m     peft_model = configure_lora(model)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mload_model_and_tokenizer\u001b[39m\u001b[34m(model_path)\u001b[39m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     55\u001b[39m     tokenizer = AutoTokenizer.from_pretrained(model_path)\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     model = \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel and tokenizer loaded from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tokenizer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:571\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    570\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    575\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:309\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    307\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    311\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4573\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4563\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4564\u001b[39m         torch.set_default_dtype(dtype_orig)\n\u001b[32m   4566\u001b[39m     (\n\u001b[32m   4567\u001b[39m         model,\n\u001b[32m   4568\u001b[39m         missing_keys,\n\u001b[32m   4569\u001b[39m         unexpected_keys,\n\u001b[32m   4570\u001b[39m         mismatched_keys,\n\u001b[32m   4571\u001b[39m         offload_index,\n\u001b[32m   4572\u001b[39m         error_msgs,\n\u001b[32m-> \u001b[39m\u001b[32m4573\u001b[39m     ) = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4574\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4578\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4579\u001b[39m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4580\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4581\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisk_offload_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4582\u001b[39m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4583\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4584\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_quantizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4585\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_fp32_regex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4586\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice_mesh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4587\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4588\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4589\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4591\u001b[39m \u001b[38;5;66;03m# record tp degree the model sharded to\u001b[39;00m\n\u001b[32m   4592\u001b[39m model._tp_size = tp_size\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\AbhishekKollojuV-Sof\\Abhishek Programs\\Project-11\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4930\u001b[39m, in \u001b[36mPreTrainedModel._load_pretrained_model\u001b[39m\u001b[34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[39m\n\u001b[32m   4928\u001b[39m is_offloaded_safetensors = checkpoint_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m checkpoint_files[\u001b[32m0\u001b[39m].endswith(\u001b[33m\"\u001b[39m\u001b[33m.safetensors\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m disk_offload_folder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_offloaded_safetensors:\n\u001b[32m-> \u001b[39m\u001b[32m4930\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4931\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe current `device_map` had weights offloaded to the disk. Please provide an `offload_folder`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4932\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m for them. Alternatively, make sure you have `safetensors` installed if the model you are using\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4933\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m offers the weights in this format.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4934\u001b[39m     )\n\u001b[32m   4935\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_offloaded_safetensors:\n\u001b[32m   4936\u001b[39m     param_device_map = expand_device_map(device_map, checkpoint_keys)\n",
      "\u001b[31mValueError\u001b[39m: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments, Qwen2Tokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Step 1: Locate GGUF model and simulate PyTorch conversion\n",
    "def locate_and_convert_gguf():\n",
    "    ollama_dir = r\"C:\\Users\\AbhishekKollojuV-Sof\\.ollama\\models\\blobs\"\n",
    "    model_name = \"qwen:0.5b\"\n",
    "    \n",
    "    try:\n",
    "        gguf_files = glob.glob(os.path.join(ollama_dir, \"sha256-*\"))\n",
    "        if not gguf_files:\n",
    "            raise FileNotFoundError(f\"No GGUF files found in {ollama_dir}\")\n",
    "        \n",
    "        gguf_path = gguf_files[0]\n",
    "        print(f\"Found GGUF file: {gguf_path}\")\n",
    "        \n",
    "        pytorch_output_dir = os.path.join(os.getcwd(), \"qwen2-0.5b-pytorch\")\n",
    "        os.makedirs(pytorch_output_dir, exist_ok=True)\n",
    "        \n",
    "        config = {\n",
    "            \"architectures\": [\"Qwen2ForSequenceClassification\"],\n",
    "            \"model_type\": \"qwen2\",\n",
    "            \"hidden_size\": 1024,\n",
    "            \"num_hidden_layers\": 24,\n",
    "            \"num_attention_heads\": 16,\n",
    "            \"vocab_size\": 151936\n",
    "        }\n",
    "        with open(os.path.join(pytorch_output_dir, \"config.json\"), \"w\") as f:\n",
    "            json.dump(config, f)\n",
    "        \n",
    "        try:\n",
    "            tokenizer = Qwen2Tokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n",
    "            tokenizer.save_pretrained(pytorch_output_dir)\n",
    "            print(f\"Tokenizer saved to {pytorch_output_dir}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating tokenizer: {e}\")\n",
    "            raise\n",
    "        \n",
    "        dummy_weights = os.path.join(pytorch_output_dir, \"pytorch_model.bin\")\n",
    "        torch.save({}, dummy_weights)\n",
    "        print(f\"Simulated PyTorch model saved to {pytorch_output_dir}\")\n",
    "        return pytorch_output_dir\n",
    "    except Exception as e:\n",
    "        print(f\"Error locating or simulating GGUF model: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 2: Load the model and tokenizer\n",
    "def load_model_and_tokenizer(model_path):\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=3,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        print(f\"Model and tokenizer loaded from {model_path}\")\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or tokenizer: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 3: Prepare and display Financial PhraseBank dataset\n",
    "def prepare_dataset(tokenizer):\n",
    "    try:\n",
    "        dataset = load_dataset(\n",
    "            \"financial_phrasebank\",\n",
    "            \"sentences_50agree\",\n",
    "            split=\"train[:1000]\",\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        raise\n",
    "    \n",
    "    print(\"\\nSample Financial PhraseBank Dataset Entries:\")\n",
    "    for i in range(3):\n",
    "        print(f\"Example {i+1}:\")\n",
    "        print(f\"Sentence: {dataset[i]['sentence']}\")\n",
    "        print(f\"Label: {dataset[i]['label']} ({['Negative', 'Neutral', 'Positive'][dataset[i]['label']]})\")\n",
    "        print()\n",
    "    \n",
    "    def preprocess_function(examples):\n",
    "        return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    \n",
    "    try:\n",
    "        tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "        tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "        tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "        return tokenized_dataset\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing dataset: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 4: Configure LoRA for ~1% trainable parameters\n",
    "def configure_lora(model):\n",
    "    lora_config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"SEQ_CLS\"\n",
    "    )\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "    peft_model.print_trainable_parameters()\n",
    "    return peft_model\n",
    "\n",
    "# Step 5: Fine-tune the model\n",
    "def fine_tune_model(model, tokenized_dataset):\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./qwen05b_lora_finetuned\",\n",
    "        num_train_epochs=1,\n",
    "        per_device_train_batch_size=4,\n",
    "        gradient_accumulation_steps=2,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset,\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        trainer.train()\n",
    "        print(\"Fine-tuning completed\")\n",
    "        return trainer\n",
    "    except Exception as e:\n",
    "        print(f\"Error during fine-tuning: {e}\")\n",
    "        raise\n",
    "\n",
    "# Step 6: Save the fine-tuned model\n",
    "def save_model(trainer, tokenizer):\n",
    "    output_dir = os.path.join(os.getcwd(), \"qwen05b_lora_finetuned\")\n",
    "    try:\n",
    "        trainer.model.save_pretrained(output_dir)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        print(f\"Fine-tuned LoRA model saved to {output_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        model_path = locate_and_convert_gguf()\n",
    "        model, tokenizer = load_model_and_tokenizer(model_path)\n",
    "        tokenized_dataset = prepare_dataset(tokenizer)\n",
    "        peft_model = configure_lora(model)\n",
    "        trainer = fine_tune_model(peft_model, tokenized_dataset)\n",
    "        save_model(trainer, tokenizer)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main execution: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
